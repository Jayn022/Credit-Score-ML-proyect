{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import janitor\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import smogn\n",
    "import optuna\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.metrics import  mean_absolute_error,accuracy_score, classification_report, confusion_matrix, roc_auc_score, mean_squared_error, r2_score, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from statsmodels.tools.tools import add_constant\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore') #Se cargan todas las librerias necesarias para utilizar (Algunas no estan siendo utilizadas porque se utilizaron anteriormente como medida de prevension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  filepath = 'datos_sinteticos.csv'\n",
    "  df= pd.read_csv(filepath)\n",
    "  df= pd.DataFrame(df)\n",
    "  df_clean= df.clean_names()\n",
    "  print(f\"El archivo se ha cargado y limpieado correctamente\")\n",
    "except FileNotFoundError:\n",
    "   print(f\"El archivo no ha sido encontrado\")  #Cargamos el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informacion general del dataset\n",
    "print(f'''\\nINFORMACIN GENERAL DEL DATASET:\\n\n",
    "    - Dimensiones: {df_clean.shape[0]} filas x {df_clean.shape[1]} columnas \\n\n",
    "    - Per铆odo de an谩lisis: dataset historico de pr茅stamos bancarios\n",
    "''')\n",
    "\n",
    "print(f'''\n",
    "    \\n ESTRUCTURA DEL DATASET: \\n{df_clean.info} \\n\n",
    "    \\n ESTADSTICA DESCRIPTIVA: \\n {df_clean.describe()}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f580c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco valores faltantes dentro del archivo\n",
    "print('Valores faltantes:')\n",
    "missing_values = df_clean.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df_clean)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Valores Faltantes': missing_values, \n",
    "    'Porcentaje': missing_percentage\n",
    "}).sort_values('Porcentaje',ascending=False)\n",
    "print(missing_df[missing_df['Valores Faltantes'] > 0])\n",
    "\n",
    "calificacion_distribution = df_clean['calificacion'].value_counts()\n",
    "calificacion_percentage = calificacion_distribution.value_counts(normalize=True)  * 100\n",
    "#Reviso los valores unicos y la distribucion de estos, es decir cuantos hay\n",
    "print(f'''\n",
    "    \\n 路 Valores 煤nicos en Calificacion: {df_clean['calificacion'].unique()}\\n\n",
    "    \\n 路 Distribuci贸n): \\n{calificacion_distribution}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Otorgo un significado a las variables de la columna que quiero predecir\n",
    "df_clean['calificacion_label'] = df_clean['calificacion'].map({''\n",
    "  'A1':'Aprobado',\n",
    "  'A2':'Aprobado',\n",
    "  'B1':'Aprobado',\n",
    "  'C1':'Aprobado con seguimiento',\n",
    "  'D1': 'No Aprobado',\n",
    "  'E1': 'No Aprobado'})\n",
    "label_distribution = df_clean['calificacion_label'].value_counts()\n",
    "label_percentage = label_distribution.value_counts(normalize=True) * 100\n",
    "\n",
    "calificacion_distribution = df_clean['calificacion'].value_counts().sort_index()\n",
    "calificacion_percentage = df_clean['calificacion'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"\\n DISTRIBUCIN NUMRICA:\")\n",
    "for valor in sorted(calificacion_distribution.index):\n",
    "    print(f\"  {valor}: {calificacion_distribution[valor]:,} casos ({calificacion_percentage[valor]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_distribution = df_clean['calificacion_label'].value_counts()\n",
    "fig, ax = plt.subplots(2,2, figsize=(15,12))\n",
    "fig.suptitle('# de calificaciones en archivo', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Gr谩fico 1: Cliente vs puntaje final\n",
    "sns.scatterplot(data=df_clean, x='edad_cliente', y='puntaje', hue='calificacion', alpha=0.6, ax=ax[0,0])\n",
    "ax[0,0].set_title('Puntaje  vs Edad del Cliente', fontsize=14, fontweight='bold')\n",
    "ax[0,0].set_xlabel('Edad del Cliente', fontsize=12)\n",
    "ax[0,0].set_ylabel('Puntaje Final', fontsize=12)\n",
    "ax[0,0].legend(title='Calificaci贸n')\n",
    "\n",
    "\n",
    "# Gr谩fico 2: Distribuci贸n por edad\n",
    "ax[0,1].hist(df_clean['edad_cliente'], bins=20, alpha=.7, color='#66b3ff', edgecolor='black')\n",
    "ax[0,1].set_title('Distribuci贸n por Edad', fontsize=14, fontweight='bold')\n",
    "ax[0,1].set_xlabel('Edad', fontsize=12)\n",
    "ax[0,1].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "# Gr谩fico 3: Ingresos VS Calificacion\n",
    "sns.boxplot(data=df_clean, x='calificacion', y='ingresos', palette='Set2', ax=ax[1,0])\n",
    "ax[1,0].set_yscale('log')\n",
    "ax[1,0].set_title('Ingresos por Estado de Calificaci贸n', fontsize=14, fontweight='bold')\n",
    "ax[1,0].set_xlabel('Calificaci贸n', fontsize=12)\n",
    "ax[1,0].set_ylabel('Ingresos (escala logar铆tmica)', fontsize=12)\n",
    "\n",
    "\n",
    "# Gr谩fico 4: Relaci贸n Deuda-Ingreso VS Default\n",
    "sns.boxplot(x='mora', y='ingresos', data=df_clean, ax=ax[1, 1], palette=[\"#de6767\", \"#1bda91\"])\n",
    "ax[1,1].set_title('Relaci贸n Mora e Ingreso', fontsize=14, fontweight='bold')\n",
    "ax[1,1].set_xlabel('Relaci贸n Mora', fontsize=12)\n",
    "ax[1,1].set_ylabel('Estado de ingreso', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1eedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comienzo con la separacion de los datos que quiero utilizar (x) para predecir la columna objetivo\n",
    "y= df_clean['calificacion']\n",
    "x= df_clean[['saldo','ahorro_general','sexo','saldo_por_vencer','saldo_pendiente','provision','dias_mora','edad_cliente','estado_civil','mora','antiguedad_meses','ingresos','descuentos','puntaje']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5aa977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba sacando valores no relevantes segun maquina\n",
    "df_test = df_clean[df_clean['puntaje'] <= 500].copy()\n",
    "Cols_predict = df_test[['saldo','ahorro_general','sexo','saldo_por_vencer','saldo_pendiente','provision','dias_mora','edad_cliente','estado_civil','mora','antiguedad_meses','ingresos','descuentos','puntaje']]\n",
    "df_balanced = smogn.smoter(data=Cols_predict, y='puntaje')\n",
    "x_balanced=df_balanced.drop('puntaje', axis=1)\n",
    "y_balanced=df_balanced['puntaje']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.get_dummies(x, drop_first=True) #Asigna valores binarios para los datos con palabras\n",
    "x_balanced=pd.get_dummies(x_balanced, drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x_balanced)\n",
    "\n",
    "kmeans = KMeans(n_clusters=9, random_state=42)\n",
    "x_balanced['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42) #Dividimos los datos 80% entrenamiento 20% prueba\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_balanced, y_balanced, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero un pipeline (defino una cadena de eventos para el momento que lo llame) con el que pueda entrenar, modelar, equilibrar, ejecutar y medir su score para saber que tan acertiva es.\n",
    "def pipeline(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",50,70)\n",
    "    max_depth= trial.suggest_int(\"max_depth\",25,32)\n",
    "    min_samples_split= trial.suggest_int(\"min_samples_split\",15,25)\n",
    "    min_samples_leaf= trial.suggest_int(\"min_samples_leaf\",4,8)\n",
    "    \n",
    "    pipeline = imbpipeline([\n",
    "            ('Sm',SMOTE(random_state=42)),\n",
    "            ('RFC',RandomForestClassifier( \n",
    "                n_estimators= n_estimators,         \n",
    "                max_depth=max_depth,            \n",
    "                min_samples_split=min_samples_split,     \n",
    "                min_samples_leaf=min_samples_leaf,       \n",
    "                max_features=0.2,      \n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                class_weight='balanced'\n",
    "            ))\n",
    "        ])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, x_train, y_train, cv=skf, scoring='accuracy')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def pipeline_lineal(trial):\n",
    "#    n_estimators = trial.suggest_int(\"n_estimators\",80,160)\n",
    "#    max_depth= trial.suggest_int(\"max_depth\",60,80)\n",
    "#    min_samples_split= trial.suggest_int(\"min_samples_split\",25,40)\n",
    "#    min_samples_leaf= trial.suggest_int(\"min_samples_leaf\",10,20)\n",
    "#    \n",
    "#    pipeline2 = imbpipeline([\n",
    "#                ('RFC',RandomForestRegressor(\n",
    "#                n_estimators = n_estimators,\n",
    "#                max_depth=max_depth,            \n",
    "#                min_samples_split=min_samples_split,     \n",
    "#                min_samples_leaf=min_samples_leaf,       \n",
    "#                max_features=0.2,      \n",
    "#                random_state=42,\n",
    "#                n_jobs=-1,\n",
    "#            ))\n",
    "#        ])\n",
    "#    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#    scores2 = cross_val_score(pipeline2, x_train2, y_train2, cv=kf, scoring='r2')\n",
    "#    return scores2.mean()\n",
    "\n",
    "def objetivo(trial):\n",
    "   n_estimators= trial.suggest_int('n_estimators',100,400)\n",
    "   learning_rate= trial.suggest_float('learning_rate',0.01,0.4, log=True)\n",
    "   max_depth=trial.suggest_int('max_depth',3,20)\n",
    "   subsample= trial.suggest_float('subsample',0.5,1.0)\n",
    "   colsample_bytree= trial.suggest_float('colsample_bytree',0.3,1.0)\n",
    "   gamma=trial.suggest_float('gamma',0,5.0)\n",
    "   reg_alpha=trial.suggest_float('reg_alpha',0.0,10.0)\n",
    "   reg_lambda= trial.suggest_float('reg_lambda',0.0,10.0)\n",
    "        \n",
    "   modelo= xgb.XGBRegressor(\n",
    "      n_estimators=n_estimators,\n",
    "      max_depth=max_depth,\n",
    "      learning_rate=learning_rate,\n",
    "      subsample=subsample,\n",
    "      colsample_bytree=colsample_bytree,\n",
    "      gamma=gamma,\n",
    "      reg_alpha=reg_alpha,\n",
    "      reg_lambda=reg_lambda,\n",
    "      random_state=42,\n",
    "      n_jobs=-1\n",
    "   )\n",
    "   kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "   score = cross_val_score(modelo,x_train2,y_train2, cv=kf, scoring='r2')\n",
    "   \n",
    "   return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizo optuna para que me ayude a sacar la mejor version posible del pipeline con 150 intentos.\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(pipeline, n_trials=5)\n",
    "\n",
    "study2 = optuna.create_study(direction=\"maximize\")\n",
    "study2.optimize(objetivo, n_trials=300) \n",
    "\n",
    "#study3 = optuna.create_study(direction=\"maximize\")\n",
    "#study3.optimize(pipeline_lineal, n_trials=60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a213c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encapsulo los mejores parametros y los utilizo para el modelo de machine learning\n",
    "best_parameters=study.best_params\n",
    "best_parameters2=study2.best_params\n",
    "#best_parameters3=study3.best_params\n",
    "\n",
    "pipeline = imbpipeline([\n",
    "    ('Sm',SMOTE(random_state=42)),\n",
    "    ('RFC',RandomForestClassifier( \n",
    "        n_estimators= best_parameters['n_estimators'],         \n",
    "        max_depth=best_parameters['max_depth'],            \n",
    "        min_samples_split=best_parameters['min_samples_split'],     \n",
    "        min_samples_leaf=best_parameters['min_samples_leaf'],       \n",
    "        max_features=0.2,      \n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "      ))\n",
    "])\n",
    "\n",
    "modelo = xgb.XGBRegressor( \n",
    "        n_estimators= best_parameters2['n_estimators'],         \n",
    "        max_depth=best_parameters2['max_depth'],     \n",
    "        learning_rate=best_parameters2['learning_rate'],     \n",
    "        subsample=best_parameters2['subsample'],\n",
    "        colsample_bytree=best_parameters2['colsample_bytree'],\n",
    "        gamma=best_parameters2['gamma'],\n",
    "        reg_alpha=best_parameters2['reg_alpha'],\n",
    "        reg_lambda=best_parameters2['reg_lambda'],      \n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "      )\n",
    "\n",
    "def Linealpipeline_opt (trial):\n",
    "  k = trial.suggest_int('k', 3, x_train2.shape[1])\n",
    "\n",
    "  pipeline_xgb = imbpipeline([('scaler',StandardScaler()),\n",
    "    ('select',SelectKBest(f_regression, k=k)),\n",
    "    ('model',modelo)])\n",
    "  \n",
    "  pipeline_xgb.fit(x_train2,y_train2)\n",
    "\n",
    "  y_pred2 = pipeline_xgb.predict(x_test2)\n",
    "  r2 = r2_score(y_test2,y_pred2)\n",
    "  return r2\n",
    "\n",
    "  \n",
    "#pipeline2 = imbpipeline([\n",
    "#                ('RFC',RandomForestRegressor(\n",
    "#                n_estimators = best_parameters3['n_estimators'],\n",
    "#                max_depth=best_parameters3['max_depth'],        \n",
    "#                min_samples_split=best_parameters3['min_samples_split'],  \n",
    "#                min_samples_leaf=best_parameters3['min_samples_leaf'],       \n",
    "#                max_features=0.2,\n",
    "#                random_state=42,\n",
    "#                n_jobs=-1,\n",
    "#            ))\n",
    "#        ])\n",
    "\n",
    "#score_lineal= cross_val_score(pipeline2,x_train2,y_train2,scoring='r2', cv=10)\n",
    "#print(f\"Score de r2 sobre los datos {score_lineal.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b323f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study3 = optuna.create_study(direction=\"maximize\")\n",
    "study3.optimize(Linealpipeline_opt, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo entreno y comienzo a realizar las pruebas de que tan acertivo es\n",
    "pipeline.fit(x_train, y_train)\n",
    "modelo.fit(x_train2, y_train2)\n",
    "\n",
    "#Predicciones con los modelos\n",
    "y_predRFC = pipeline.predict(x_test)\n",
    "y_probaRFC = pipeline.predict_proba(x_test)[:, :]\n",
    "y_predRFC2 = modelo.predict(x_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = modelo.feature_importances_\n",
    "plt.barh(x_train2.columns, importances)\n",
    "plt.title(\"Importancia de caracter铆sticas\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vuelvo a medir el modelo con los datos de entrenamiento, pero con el mejor pipeline para saber que tanto puede equivocarse\n",
    "scores= cross_val_score( pipeline, x_train,y_train, scoring='accuracy')\n",
    "scores2= cross_val_score( modelo, x_train2,y_train2, scoring='r2')\n",
    "#Matriz de Confusion\n",
    "#con esto mido que tanto se ha podido equivocar el modelo\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,y_predRFC))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de Confusi贸n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69784f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy (RFC):\", accuracy_score(y_test, y_predRFC)) #Compara las precisiones\n",
    "\n",
    "print(\"Reporte de clasificaci贸n (RFC):\\n\", classification_report(y_test, y_predRFC)) #Puntuacion de datos por clase \n",
    "\n",
    "print(\"Matriz de confusi贸n (RFC):\\n\", confusion_matrix(y_test, y_predRFC)) #Comparacion de aciertos por modelos\n",
    "\n",
    "print(\"ROC AUC (RFC):\", roc_auc_score(y_test, y_probaRFC, multi_class=\"ovr\")) # Hace una comparacion entre los verdaderos positivos y los falsos positivos (Roc: Receiver operating Characteristics; Mide el area bajo la curva, a mayor cercania de 1 mejor clasificacion (Auc: Area under the Curve))\n",
    "\n",
    "print(\"Los mejores parametros son: \", best_parameters)\n",
    "print(\"Accuracy en cada fold:\", scores)\n",
    "print(\"Accuracy promedio:\", np.mean(scores))\n",
    "print(\"Desviaci贸n est谩ndar:\", np.std(scores))\n",
    "\n",
    "\n",
    "print(\"Maquina de regresion lineal\")\n",
    "\n",
    "mse = mean_squared_error(y_test2,y_predRFC2)\n",
    "mser = np.sqrt(mse)\n",
    "\n",
    "print(\"R2 Score:\", r2_score(y_test2, y_predRFC2))                # Qu茅 tan bien el modelo explica la varianza\n",
    "print(\"MAE:\", mean_absolute_error(y_test2, y_predRFC2))          # Error promedio absoluto\n",
    "print(\"RMSE:\", mser)  # Ra铆z del error cuadr谩tico medio\n",
    "\n",
    "\n",
    "print(\"Accuracy en cada fold:\", scores2)\n",
    "print(\"Accuracy promedio:\", np.mean(scores2))\n",
    "print(\"Desviaci贸n est谩ndar:\", np.std(scores2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99169338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mido cuantos datos fueron a cada uno, es decir de todas las filas, cuales pertenecen a cada dato, y la relevancia de cada columna para el resultado.\n",
    "unique, counts = np.unique(y_train2, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(np.unique(y_train2, return_counts=True))\n",
    "\n",
    "importancia = modelo.feature_importances_\n",
    "columnas = x_train2.columns\n",
    "\n",
    "df_list = pd.DataFrame({'Variables' : columnas, 'Importancia': importancia})\n",
    "df_list = df_list.sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "print(df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
